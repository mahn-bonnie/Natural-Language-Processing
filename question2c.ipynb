{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCuBx2u3YHtN",
        "outputId": "27cc5a91-4c26-4472-afc5-009731cd2920"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. My friend bought a new shirt.\n",
            "Error parsing sentence 1: Grammar does not cover some of the input words: \"'bought', '.'\".\n",
            "\n",
            "2. My friend bought a smart new blue shirt.\n",
            "Error parsing sentence 2: Grammar does not cover some of the input words: \"'bought', '.'\".\n",
            "\n",
            "3. My friend bought a shirt and a pair of shoes.\n",
            "Error parsing sentence 3: Grammar does not cover some of the input words: \"'bought', 'of', '.'\".\n",
            "\n",
            "4. My friend bought a shirt with a logo in the sale at the supermarket.\n",
            "Error parsing sentence 4: Grammar does not cover some of the input words: \"'bought', 'the', 'the', '.'\".\n",
            "\n",
            "5. My friend bought a new pair of shoes.\n",
            "Error parsing sentence 5: Grammar does not cover some of the input words: \"'bought', 'of', '.'\".\n",
            "\n",
            "6. My friend bought a shirt with a red collar and a blue tie.\n",
            "Error parsing sentence 6: Grammar does not cover some of the input words: \"'bought', '.'\".\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk import CFG, word_tokenize\n",
        "\n",
        "\n",
        "# Grammar Rules\n",
        "noun_phrase_grammar = CFG.fromstring(\"\"\"\n",
        "    NP -> Det AdjStar N PPStar\n",
        "    AdjStar -> Adj AdjStar | ''\n",
        "    PPStar -> PP NP | ''\n",
        "    Det -> 'My' | 'a' | 'new' | 'smart' | 'blue' | 'and'\n",
        "    Adj -> 'smart' | 'new' | 'blue' | 'red'\n",
        "    N -> 'friend' | 'shirt' | 'pair' | 'shoes' | 'logo' | 'sale' | 'supermarket' | 'collar' | 'tie'\n",
        "    PP -> P NP\n",
        "    P -> 'with' | 'in' | 'at'\n",
        "\"\"\")\n",
        "\n",
        "# Parsing\n",
        "from nltk import ChartParser\n",
        "\n",
        "# Examples to parse\n",
        "examples_to_parse = [\n",
        "    \"My friend bought a new shirt.\",\n",
        "    \"My friend bought a smart new blue shirt.\",\n",
        "    \"My friend bought a shirt and a pair of shoes.\",\n",
        "    \"My friend bought a shirt with a logo in the sale at the supermarket.\",\n",
        "    \"My friend bought a new pair of shoes.\",\n",
        "    \"My friend bought a shirt with a red collar and a blue tie.\"\n",
        "]\n",
        "\n",
        "# Parsing and drawing trees\n",
        "parser = ChartParser(noun_phrase_grammar)\n",
        "\n",
        "for i, example in enumerate(examples_to_parse, 1):\n",
        "    tokens = word_tokenize(example)\n",
        "    print(f\"{i}. {example}\")\n",
        "    try:\n",
        "        for tree in parser.parse(tokens):\n",
        "            tree.pretty_print()\n",
        "            print(\"\\n\")\n",
        "    except ValueError as e:\n",
        "        print(f\"Error parsing sentence {i}: {e}\\n\")\n",
        "\n"
      ]
    }
  ]
}